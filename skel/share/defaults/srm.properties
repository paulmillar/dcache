# -----------------------------------------------------------------------
#    Default values for srm
# -----------------------------------------------------------------------
@DEFAULTS_HEADER@

# ---- Cell names
#
srm.cell.name=SRM-${host.name}

#  ---- Whether to export the srm as a well known cell
#
#  This property controls whether the srm cell is published as
#  a well known cell. Well known cells are addressable through their
#  cell name, while other cells are only addressable from other domains
#  using their fully qualified cell address.
(one-of?true|false)srm.cell.export=true

srm.cell.subscribe=${srm.loginbroker.update-topic},${srm.loginbroker.request-topic},${srm.credential-service.topic},${srm.pool-monitor.topic}

# Cell message processing limits
(deprecated)srm.cell.limits.message.threads.max = 10
(deprecated)srm.cell.limits.message.queue.max = 100

srm.cell.max-message-threads = ${srm.cell.limits.message.threads.max}
srm.cell.max-messages-queued = ${srm.cell.limits.message.queue.max}

#
# SRM versions to support.
#
# Comma separated list of SRM versions to support.
#
(any-of?1|2)srm.version=2

#  ---- TCP Port
#
#  The port SRM will listen on for GSI-based communication.  GSI is an
#  encrypted transport commonly used in grid communication.  It is
#  similar to SSL but incompatible.
#
srm.net.port = 8443
#
#  The port SRM will listen on for SSL-based communication.  SSL is an
#  industry standard encryption transport.
#
srm.net.ssl-port = 8445

#  The interface SRM will listen on.
srm.net.listen=${dcache.net.listen}


# ---- Host name of srm service
#
# For certain operations srm needs to know its domain name.  The
# srm.net.host property can be used to override the default value.  If
# this value is not set, the value is detected automatically and it is
# equivalent to the output of the unix hostname program.
#
srm.net.host = ${host.fqdn}


# ---- Host names of srm services in this deployment
#
# A host part of the source url (surl) is used to determine if the
# surl references file in this storage system.  In case of the copy
# operation, srm needs to be able to dinstinguish between the local
# surl and the remote one.  Also srm needs to refuse to perform
# operations on non local srm urls.  The srm.net.local-hosts property
# value is a comma separated list of hosts that will be considered
# local by this srm service.  This parameter might need to be defined
# as a list because in case of the multihomed or distributed server it
# may have more than one network name.  If srm.net.local-host is not
# specified, srm.net.host will be used.
#
srm.net.local-hosts=${srm.net.host}


# ---- Client side transport layer encryption
#
# The security transport to use when contacting remote SRM instances.  GSI
# (Grid Security Infrastructure) is the commonly deployed protocol, but SSL
# is the industrial standard.  This property is only used for third-party
# copies (srmCopy).
#
(one-of?SSL|GSI)srm.client-transport = GSI


# ---- Database host name
#
srm.db.host = ${dcache.db.host}

# ---- Database name
srm.db.name = srm


# ---- Database user name
srm.db.user = ${dcache.db.user}

# ---- Database password
srm.db.password = ${dcache.db.password}

# ---- Database password file
srm.db.password.file = ${dcache.db.password.file}

# ---- Database JDBC URL
srm.db.url = jdbc:postgresql://${srm.db.host}/${srm.db.name}

#
# The maximum number of concurrent database connections.
#
srm.db.connections.max = 50

#
# The minimum number of idle database connections.
#
srm.db.connections.idle = 1

#  ---- Whether to manage the database schema automatically during startup
#
# If set to 'false' then the "dcache database update" command must be used to
# check if database schema needs to be updated and apply any necessary changes.
(one-of?true|false|${dcache.db.schema.auto})srm.db.schema.auto=${dcache.db.schema.auto}

# Liquibase schema definition
srm.db.schema.changelog=org/dcache/srm/request/sql/srm.changelog-master.xml


# ---- TCP streams to use for GridFTP transfer
#
#   The number of concurrent TCP streams used by srmCopy controlled
#   GridFTP transfers.
#
srm.limits.parallel-streams = 10

# ---- Timeout of the external srmCopy script
#
#   Timeout in seconds, how long to wait for the completion of the
#   transfer via external client, should the external client be used
#   for the MSS to MSS transfers.
#
srm.limits.external-copy-script.timeout = 3600
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srm.limits.external-copy-script.timeout.unit=SECONDS


# ---- Buffer size used for srmCopy transfer
#
#   Specified in bytes.
#
srm.limits.transfer-buffer.size = 1048576

# ---- TCP buffer size used for srmCopy transfer
#
#   Specified in bytes.
#
srm.limits.transfer-tcp-buffer.size = 1048576

# ---- Controls debug functionality of the external srmCopy script
#
(one-of?true|false)srm.enable.external-copy-script.debug = true

# ---- Threads that accept TCP connections
srm.limits.jetty-connector.acceptors = 1

# ---- Milliseconds before an idle TCP connection is closed
srm.limits.jetty-connector.idle-time.max = 60000
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srm.limits.jetty-connector.idle-time.max.unit=MILLISECONDS

# ---- Milliseconds before an idle TCP connection is closed during high load
srm.limits.jetty-connector.low-resource.max.idle-time = 20000
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srm.limits.jetty-connector.low-resource.max.idle-time.unit=MILLISECONDS

# ---- TCP backlog for SRM connections
srm.limits.jetty-connector.backlog = 2048

# ---- Maximum number of threads used for SRM request processing
#
# Whenever a client submits an SRM request a thread is allocated. This
# setting controls the maximum number of such threads.
#
# Notice that this does not control the number of SRM transfers that
# can be active at any given time: An SRM transfer involves several
# requests by the client (eg srmPrepareToGet, srmStatusOfGetRequest,
# srmReleaseFiles).
#
# There is also a choice whether to process requests synchronously or
# asynchronously. If processed synchronously, the request is not answered
# until processed. This means that a thread is bound to the request for
# the duration of the request processing. If processed asynchronous,
# the thread is released right away and the client submits new requests
# to poll for the completion of the previously submitted request. This
# adds latency and increases authentication overhead, but frees thread
# and TCP connections. See srm.request.switch-to-async-mode-delay.
#
srm.limits.jetty.threads.max = 500

# ---- Minimum number of threads used for SRM request processing
srm.limits.jetty.threads.min = 10


# ---- Milliseconds before an idle request processing thread is terminated
srm.limits.jetty.threads.idle-time.max = 30000
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srm.limits.jetty.threads.idle-time.max.unit=MILLISECONDS

# ---- Maximum number of queued SRM requests
#
# Once the limit is reached no new connections will be accepted;
# instead, the operating system will queue them in the TCP backlog.
# Once the TCP backlog is filled, the operating system will reject
# further TCP connections.
#
srm.limits.jetty.threads.queued.max = 500

# ---- Enable legacy socket closure
#
# GSI is layered on top of the SSL/TLS protocol. SSL/TLS specifies that
# if the server wants to close the connection, it is to send an SSL
# close notification to the client. Some clients consider this notification
# a fatal error and expect the server to instead abruptly close the socket.
#
# Setting this property to true causes the server to close the socket without
# sending a close notification first. This should be enabled if compatibility
# with these clients is required.
#
(one-of?true|false)srm.enable.legacy-close=true

# ---- Parameters for schedulable SRM requests
#
# The SRM specification allows some request types to be processed
# asynchronously. Rather than waiting for request processing to
# complete before getting a reply, the client receives a preliminary
# reply stating that the request is accepted with instructions to
# ask back for the result later. The SRM specification allows this
# mode of operation for the following requests:
#
#  o srmReserveSpace
#  o srmUpdateSpace
#  o srmChangeSpaceForFiles
#  o srmLs
#  o srmPrepareToGet
#  o srmPrepareToPut
#  o srmCopy
#  o srmBringOnline
#
# Except for srmUpdateSpace and srmChangeSpaceForFiles, dCache supports
# asynchronous processing for all these requests.
#
# These requests share a common lifecycle:
#
#  o SRM_REQUEST_QUEUED
#
#    The request is queued for processing. dCache is currently not processing
#    the request.
#
#  o SRM_REQUEST_INPROGRESS
#
#    dCache is processing the request.
#
#  o SRM_FILE_PINNED / SRM_SPACE_AVAILABLE
#
#    For srmPrepareToGet and srmPrepareToPut these states indicate
#    that a transfer URL has been prepared and the client is expected
#    to transfer the file.
#
#  o SRM_SUCCESS / SRM_FAILURE / SRM_RELEASED / SRM_ABORTED
#
#    Request has completed and is no longer active
#
# This lifecycle is controlled by the SRM request scheduler. A separate
# scheduler exists for each request type, allowing limits to be configured
# individually.
#
# The SRM specification supports bulk operations for the following requests:
#
#  o srmLs
#  o srmPrepareToGet
#  o srmPrepareToPut
#  o srmCopy
#  o srmBringOnline
#  o srmRm
#
# A single client request may apply to a large number of files. Internally,
# dCache treats each file in a schedulable bulk request individually. To be
# precise, the scheduling described above does not apply to the entire SRM
# request, but to each site URL in the request. This is also true for the
# configuration properties described below.
#
# srmRm isn't a schedulable request and thus the discussion above doesn't
# apply to it.


# ---- Maximum number of requests allowed
#
# This is the maximum number requests allowed of any given
# request type. Once the limit is reached, new requests will fail
# immediately rather than being queued.
#
# Any request that is not finished counts towards this limit. That is, all
# requests in one of the following states: SRM_REQUEST_QUEUED,
# SRM_REQUEST_INPROGRESS, SRM_FILE_PINNED and SRM_SPACE_AVAILABLE.
#
srm.request.max-requests = 50000
srm.request.get.max-requests = ${srm.request.max-requests}
srm.request.bring-online.max-requests = ${srm.request.max-requests}
srm.request.put.max-requests = ${srm.request.max-requests}
srm.request.copy.max-requests = ${srm.request.max-requests}
srm.request.ls.max-requests = ${srm.request.max-requests}
srm.request.reserve-space.max-requests = ${srm.request.max-requests}


# ---- Maximum number of requests in progress
#
# Maximum number of requests to process concurrently of any given request type.
# This limits the number of SRM_REQUEST_INPROGRESS requests. Once the limit is
# reached, new requests will queue. Requests for which a TURL was already
# computed do not count towards this limit even if their state may be reported
# as SRM_REQUEST_INPROGRESS.
#
# The setting is a good measure of how much load the SRM can induce directly
# on other services in dCache, such as pnfs manager and pin manager.
#
# Notably, this setting limits the number of files that can be brought online
# simultaneously for get and bring-online requests, and the number of concurrent
# srmCopy transfers.
#
# The setting does NOT limit the number of concurrent upload and downloads. In
# SRM, srmPrepareToPut and srmPrepareToGet do not actually transfer a file: They
# prepare a transfer URL so that the client can transfer a file. Once the transfer
# URL has been prepared, the requests are no longer considered in progress (see
# srm.request.max-transfers).
#
srm.request.get.max-inprogress = 1000
srm.request.bring-online.max-inprogress = 10000
srm.request.copy.max-inprogress = 1000
srm.request.put.max-inprogress = 50
srm.request.ls.max-inprogress = 50
srm.request.reserve-space.max-inprogress = 10

# ---- Number of simultaneous transfer URLs
#
# This limits the number of TURLs to hand out to clients. If this limit is reached,
# additional requests will be queued after having been prepared.
#
# Note that clients may not actually transfer the file right after receiving a
# TURL. Many advanced clients check out TURLs ahead of time and queue transfers
# to and from those TURLs. Thus the actual number of transfers observed on dCache
# doors may be lower than the number TURLs handed out to the client.
#
# Note that this setting does not apply to srmCopy requests. Such requests do
# not have a TURL as the transfer is done by dCache and not by the client. To
# control the number of concurrent copies use srm.request.copy.max-inprogress or
# the settings of the transfermanagers service.
#
srm.request.max-transfers=50000

srm.request.get.max-transfers = ${srm.request.max-transfers}

srm.request.put.max-transfers = ${srm.request.max-transfers}


# ---- Request discriminator
#
# A discriminator identifies a request as coming from a particular user or group of
# users: a party.  Requests with the same discriminator value come from the same party.
#
# Discriminators are typically used by fair-share schedulers when deciding which requests
# should be grouped together.  Such schedulers maintain some degree of fairness between
# requests from different parties (requests with distinct discriminator values) and not
# between requests from the same party.
#
# Discriminators are provided by plugins implementing the JobDiscriminator SPI.  Several
# such plugins ship with dCache:
#
#   uid    The request submitter's UID.
#
#   gid    The request submitter's primary GID.
#
#   dn     The request submitter's distinguished name.
#
#   fqan   The request submitter's primary FQAN.
#
#   user   The request submitter's mapped user name.
#
#   vo     The request submitter's VO association as extracted from the primary FQAN.
#
srm.plugins.discriminator=dn


# ---- Request scheduling strategy
#
# Strategy for how to schedule schedulable SRM requests. The strategy controls in which order
# SRM requests transition from the SRM_REQUEST_QUEUED state to SRM_REQUEST_INPROGRESS. Once
# the max-inprogress limit for a specific type of requests is reached, subsequent requests are
# queued and the scheduling strategy controls the order in which these requests are processed.
#
# The strategy is pluggable and third party plugins can add new strategies by implementing
# scheduling strategy SPI. Several plugins ship with dCache:
#
#   fifo    First in, first out. Requests are processed in arrival order. Individual users
#           may monopolise the SRM through issuing many requests or issuing long-lasting
#           requests.
#
#   lifo    Last in, first out. The last request to arrive is processed first. In contrast to
#           fifo, this policy is not fair. Under load spikes, some requests will observe longer
#           response times, while others appear fast.
#
#           Lifo does however tend to be more robust in overload scenarios because it processes
#           the requests for which the client is least likely to time out first. In other words,
#           it can maintain maximum request rate, while fifo in some scenarios can enter a
#           live-lock in which all resources are spent on processing requests for which the
#           client subsequently times out.
#
#   throughput-fair-share
#
#           Round robin scheduler providing fair sharing of the request rate. E.g. if two
#           parties have requests queued, requests are scheduled in alternating order. Does
#           not prevent that one party may monopolise the system by submitting long running
#           requests while the other party submits requests that finish quickly.
#
#           A configurable discriminator defines the grouping between which to provide a
#           fair share.
#
#   inprogress-fair-share
#
#           Least-inprogress-requests-first scheduler providing fair sharing of the inprogress
#           slots. E.g. if two parties have requests queued, the party with the least inprogress
#           requests is the one whose request will be started. If one party submits long running
#           requests, that party will effectively be penalized by having a lower request rate.
#
#           A configurable discriminator defines the grouping between which to provide a
#           fair share.
#
srm.plugins.scheduler = inprogress-fair-share

# Configuration of the inprogress fair share strategy.
(prefix)srm.scheduler.inprogress-fair-share = Configuration for the in progress fair share scheduling strategy

# Discriminator for the inprogress fair share strategy.
srm.scheduler.inprogress-fair-share!discriminator = ${srm.plugins.discriminator}

# Configuration of the throughput fair share strategy.
(prefix)srm.scheduler.throughput-fair-share = Configuration for the throughput fair share scheduling strategy

# Discriminator for the throughput fair share strategy.
srm.scheduler.throughput-fair-share!discriminator = ${srm.plugins.discriminator}


# ---- Request transfer strategy
#
# srmPrepareToPut and srmPrepareToGet requests enter the READY state when the TURL is handed
# out to the client. If the request is processed asynchronously (client is polling for the result),
# the request stays in the RQUEUED state until the client queries the result.
#
# A transfer strategy plugin has the ability to prevent the transition from the RQUEUED to READY
# state. A plugin may allow the number of concurrent transfers to be limited, or may provide
# some fair-share between parties.
#
# Two plugins ship with dCache:
#
#     first-come-first-served
#
#         The maximum number of requests in the READY state is limited by
#         srm.request.*.max-transfers, but otherwise TURLs are handed out to
#         whomever comes first.
#
#     fair-share
#
#         The maximum number of requests in the READY state is limited by
#         srm.request.*.max-transfers, but slots are kept free such that each party with
#         requests in RQUEUED will receive its fair share.
#
#           A configurable discriminator defines the grouping between which to provide a
#           fair share.
#
srm.plugins.transfer = fair-share

# Configuration of the fair share ready strategy.
(prefix)srm.transfer.fair-share = Configuration for the fair share transfer strategy

# Discriminator for the fair share transfer strategy.
srm.transfer.fair-share!discriminator = ${srm.plugins.discriminator}

# Configuration of the max ready strategy.
(prefix)srm.transfer.first-come-first-served = Configuration for the first come first serve transfer strategy



# ---- Delay until requests are processed asynchronously
#
# Schedulable SRM requests may be processed synchronously or asynchronously, at
# the server's discretion.  dCache can start to process such requests synchronously
# and, if this is taking too long, reply asynchronously and continue to work on the
# operation background. While in synchronous mode, a webserver thread is blocked
# waiting for the result (see srm.limits.jetty.threads.min and
# srm.limits.jetty.threads.max).
#
# This setting specifies the time after which requests are handled asynchronously.
# Set to 'infinity' to disable asynchronous processing.
#
# Asynchronous processing avoids holding TCP connections to the server while
# the request is processed, but at the expense of the client periodically polling
# the status, thus increasing the perceived request processing time.
#
srm.request.switch-to-async-mode-delay = 1000
(one-of?MILLISECONDS|SECONDS|MINUTES)\
srm.request.switch-to-async-mode-delay.unit=MILLISECONDS

srm.request.get.switch-to-async-mode-delay = ${srm.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|SECONDS|MINUTES|${srm.request.switch-to-async-mode-delay.unit})\
srm.request.get.switch-to-async-mode-delay.unit = ${srm.request.switch-to-async-mode-delay.unit}

srm.request.bring-online.switch-to-async-mode-delay = ${srm.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|\
	SECONDS|MINUTES|\
	HOURS|DAYS|\
	${srm.request.switch-to-async-mode-delay.unit})\
srm.request.bring-online.switch-to-async-mode-delay.unit=${srm.request.switch-to-async-mode-delay.unit}

srm.request.put.switch-to-async-mode-delay = ${srm.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.request.switch-to-async-mode-delay.unit})\
srm.request.put.switch-to-async-mode-delay.unit=${srm.request.switch-to-async-mode-delay.unit}

srm.request.ls.switch-to-async-mode-delay = ${srm.request.switch-to-async-mode-delay}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.request.switch-to-async-mode-delay.unit})\
srm.request.ls.switch-to-async-mode-delay.unit=${srm.request.switch-to-async-mode-delay.unit}

# ---- Maximum advertised poll period for asynchronous requests
#
# Once a schedulable SRM request switches to asynchronous processing (see srm.request.switch-to-async-mode-delay),
# the SRM servers advertises a polling period to the client. The server gradually increases the period every
# time the client polls for the result. This setting places an upper bound on this poll period.
#
# An SRM client is free to ignore the advertised poll period.
#
srm.request.max-poll-period = 60
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srm.request.max-poll-period.unit = SECONDS

srm.request.get.max-poll-period = ${srm.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srm.request.max-poll-period.unit})\
srm.request.get.max-poll-period.unit = ${srm.request.max-poll-period.unit}

srm.request.put.max-poll-period = ${srm.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srm.request.max-poll-period.unit})\
srm.request.put.max-poll-period.unit = ${srm.request.max-poll-period.unit}

srm.request.bring-online.max-poll-period = ${srm.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srm.request.max-poll-period.unit})\
srm.request.bring-online.max-poll-period.unit = ${srm.request.max-poll-period.unit}

srm.request.ls.max-poll-period = ${srm.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srm.request.max-poll-period.unit})\
srm.request.ls.max-poll-period.unit = ${srm.request.max-poll-period.unit}

srm.request.reserve-space.max-poll-period = ${srm.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srm.request.max-poll-period.unit})\
srm.request.reserve-space.max-poll-period.unit = ${srm.request.max-poll-period.unit}

srm.request.copy.max-poll-period = ${srm.request.max-poll-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${srm.request.max-poll-period.unit})\
srm.request.copy.max-poll-period.unit = ${srm.request.max-poll-period.unit}

# ---- Persistence of requests
#
# Controls whether schedulable SRM requests (put, get, ls, bring online, reserve space) are
# stored in the SRM database.
#
# If disabled, recovery after restart will not work, which will lead to leaked upload
# directories. Listing and monitoring of complete requests are also unsupported if this
# option is disabled.
#
# See also srm.persistence.* for other tuning parameters for request persistence.
#
(one-of?true|false)srm.persistence.enable = true

(one-of?true|false|${srm.persistence.enable})srm.persistence.get.enable = ${srm.persistence.enable}

(one-of?true|false|${srm.persistence.enable})srm.persistence.bring-online.enable = ${srm.persistence.enable}

(one-of?true|false|${srm.persistence.enable})srm.persistence.put.enable = ${srm.persistence.enable}

(one-of?true|false|${srm.persistence.enable})srm.persistence.copy.enable = ${srm.persistence.enable}

(one-of?true|false|${srm.persistence.enable})srm.persistence.ls.enable = ${srm.persistence.enable}

(one-of?true|false|${srm.persistence.enable})srm.persistence.reserve-space.enable = ${srm.persistence.enable}


# ---- Enable cleaning of pending requests during restart
#
# When true and the srm is restarted, all unfinished requests will be aborted right away.
# This will invalidate all ongoing SRM transfers and all ongoing stage requests. If
# false, most clients should not notice a brief restart.
#
(one-of?true|false)srm.persistence.enable.clean-pending-on-restart=false

(one-of?true|false|${srm.persistence.enable.clean-pending-on-restart})\
srm.persistence.get.enable.clean-pending-on-restart = ${srm.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srm.persistence.enable.clean-pending-on-restart})\
srm.persistence.bring-online.enable.clean-pending-on-restart = ${srm.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srm.persistence.enable.clean-pending-on-restart})\
srm.persistence.put.enable.clean-pending-on-restart = ${srm.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srm.persistence.enable.clean-pending-on-restart})\
srm.persistence.copy.enable.clean-pending-on-restart = ${srm.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srm.persistence.enable.clean-pending-on-restart})\
srm.persistence.ls.enable.clean-pending-on-restart = ${srm.persistence.enable.clean-pending-on-restart}

(one-of?true|false|${srm.persistence.enable.clean-pending-on-restart})\
srm.persistence.reserve-space.enable.clean-pending-on-restart = ${srm.persistence.enable.clean-pending-on-restart}


# ---- Period before old transfers are removed from the database
#
# The srm will hold SRM requests and their history in database for
# srm.persistence.keep-history-period days after that they will be removed.
#
srm.persistence.keep-history-period = 10
(one-of?HOURS|DAYS)srm.persistence.keep-history-period.unit=DAYS

srm.persistence.get.keep-history-period = ${srm.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srm.persistence.keep-history-period.unit})\
srm.persistence.get.keep-history-period.unit=${srm.persistence.keep-history-period.unit}

srm.persistence.bring-online.keep-history-period = ${srm.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srm.persistence.keep-history-period.unit})\
srm.persistence.bring-online.keep-history-period.unit=${srm.persistence.keep-history-period.unit}

srm.persistence.put.keep-history-period = ${srm.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srm.persistence.keep-history-period.unit})\
srm.persistence.put.keep-history-period.unit=${srm.persistence.keep-history-period.unit}

srm.persistence.copy.keep-history-period = ${srm.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srm.persistence.keep-history-period.unit})\
srm.persistence.copy.keep-history-period.unit=${srm.persistence.keep-history-period.unit}

srm.persistence.ls.keep-history-period = ${srm.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srm.persistence.keep-history-period.unit})\
srm.persistence.ls.keep-history-period.unit=${srm.persistence.keep-history-period.unit}

srm.persistence.reserve-space.keep-history-period = ${srm.persistence.keep-history-period}
(one-of?HOURS|DAYS|${srm.persistence.keep-history-period.unit})\
srm.persistence.reserve-space.keep-history-period.unit=${srm.persistence.keep-history-period.unit}


#
# --- How frequently to remove old requests from the database.
#
srm.persistence.remove-expired-period = 600
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS)\
srm.persistence.remove-expired-period.unit=SECONDS

srm.persistence.get.remove-expired-period = ${srm.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.persistence.remove-expired-period.unit})\
srm.persistence.get.remove-expired-period.unit=${srm.persistence.remove-expired-period.unit}

srm.persistence.bring-online.remove-expired-period = ${srm.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.persistence.remove-expired-period.unit})\
srm.persistence.bring-online.remove-expired-period.unit=${srm.persistence.remove-expired-period.unit}

srm.persistence.put.remove-expired-period = ${srm.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.persistence.remove-expired-period.unit})\
srm.persistence.put.remove-expired-period.unit=${srm.persistence.remove-expired-period.unit}

srm.persistence.copy.remove-expired-period = ${srm.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|DAYS|\
	${srm.persistence.remove-expired-period.unit})\
srm.persistence.copy.remove-expired-period.unit=${srm.persistence.remove-expired-period.unit}

srm.persistence.ls.remove-expired-period = ${srm.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.persistence.remove-expired-period.unit})\
	srm.persistence.ls.remove-expired-period.unit=${srm.persistence.remove-expired-period.unit}

srm.persistence.reserve-space.remove-expired-period = ${srm.persistence.remove-expired-period}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.persistence.remove-expired-period.unit})\
srm.persistence.reserve-space.remove-expired-period.unit=${srm.persistence.remove-expired-period.unit}


# ---- Persistence of SRM request transitions
#
# Controls persistence of the transition history of SRM request in the database.
# Request transitions can be examined through the command line interface or
# through the the srmWatch monitoring tool.
#
# Disabling this feature reduces the size and load of the database at the
# expense of not being able to retrieve all information about completed
# transfers. Such information is often useful when diagnosing problems.
#
# If srm.persistence.enable is set to false, this setting has no effect.
#
(one-of?true|false)\
srm.persistence.enable.history = true

(one-of?true|false|${srm.persistence.enable.history})\
srm.persistence.get.enable.history = ${srm.persistence.enable.history}

(one-of?true|false|${srm.persistence.enable.history})\
srm.persistence.bring-online.enable.history = ${srm.persistence.enable.history}

(one-of?true|false|${srm.persistence.enable.history})\
srm.persistence.put.enable.history = ${srm.persistence.enable.history}

(one-of?true|false|${srm.persistence.enable.history})\
srm.persistence.copy.enable.history = ${srm.persistence.enable.history}

(one-of?true|false|${srm.persistence.enable.history})\
srm.persistence.ls.enable.history = ${srm.persistence.enable.history}

(one-of?true|false|${srm.persistence.enable.history})\
srm.persistence.reserve-space.enable.history = ${srm.persistence.enable.history}

# --- Immediately store all transitions
#
# Controls whether intermediate state transitions trigger an update to the database.
# If set to true, every change to a request state is stored. If set to false then
# intermediate state changes are batched together and stored with other changes.
#
# The setting does not control which information is stored in the database. When a
# request is eventually stored, all available information is stored.
#
# If srm.persistence.enable is set to false, this setting has no effect.
#
(one-of?true|false)srm.persistence.enable.store-transient-state = false

(one-of?true|false|${srm.persistence.enable.store-transient-state})\
srm.persistence.get.enable.store-transient-state = ${srm.persistence.enable.store-transient-state}

(one-of?true|false|${srm.persistence.enable.store-transient-state})\
srm.persistence.bring-online.enable.store-transient-state = ${srm.persistence.enable.store-transient-state}

(one-of?true|false|${srm.persistence.enable.store-transient-state})\
srm.persistence.put.enable.store-transient-state = ${srm.persistence.enable.store-transient-state}

(one-of?true|false|${srm.persistence.enable.store-transient-state})\
srm.persistence.copy.enable.store-transient-state = ${srm.persistence.enable.store-transient-state}

(one-of?true|false|${srm.persistence.enable.store-transient-state})\
srm.persistence.ls.enable.store-transient-state = ${srm.persistence.enable.store-transient-state}

(one-of?true|false|${srm.persistence.enable.store-transient-state})\
srm.persistence.reserve-space.enable.store-transient-state = ${srm.persistence.enable.store-transient-state}


# Ls requests settings

# ---- Directory entries to include in list reply
#
# Number of entries allowed to be returnes in a single srmls
# request. Directory listings larger than this most be broken into
# multiple requests.
#
# Use 'infinity' to specify that there is no limit. Warning: Available
# heap memory will be an upper limit as the response cannot be
# streamed. Once heap limit is reached, the SRM will auto-restart.
#
srm.limits.ls.entries = 10000

# ---- List recursion depth
#
# Maximum recursion depth.
#
srm.limits.ls.levels = infinity

# --- Request lifetimes

srm.request.lifetime=14400000
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.request.lifetime.unit=MILLISECONDS

srm.request.get.lifetime = ${srm.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.request.lifetime.unit})\
srm.request.get.lifetime.unit=${srm.request.lifetime.unit}

srm.request.bring-online.lifetime = ${srm.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.request.lifetime.unit})\
srm.request.bring-online.lifetime.unit=${srm.request.lifetime.unit}

srm.request.put.lifetime = ${srm.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.request.lifetime.unit})\
srm.request.put.lifetime.unit=${srm.request.lifetime.unit}

srm.request.copy.lifetime = ${srm.request.lifetime}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${srm.request.lifetime.unit})\
srm.request.copy.lifetime.unit=${srm.request.lifetime.unit}

# ---- File system root exported by the srm service
srm.root = /

# Cell address of pnfsmanager service
srm.service.pnfsmanager=${dcache.service.pnfsmanager}

# Timeout for pnfsmanager requests
srm.service.pnfsmanager.timeout = 120
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|DAYS)\
srm.service.pnfsmanager.timeout.unit=SECONDS

# Cell address of gplazma service
srm.service.gplazma=${dcache.service.gplazma}

# Timeout for gplazma requests
srm.service.gplazma.timeout=30000
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.service.gplazma.timeout.unit=MILLISECONDS

# gPlazma authorization cache size
srm.service.gplazma.cache.size=1000

# gPlazma authorization cache lifetime
srm.service.gplazma.cache.timeout = 180
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.service.gplazma.cache.timeout.unit=SECONDS

# Cell address of spacemanager service
srm.service.spacemanager=${dcache.service.spacemanager}

# Timeout for spacemanager requests
srm.service.spacemanager.timeout=30
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.service.spacemanager.timeout.unit=SECONDS

# Cell address of transfermanager service
srm.service.transfermanager=${dcache.service.transfermanager}

# Timeout for transfermanager requests
srm.service.transfermanager.timeout=24
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.service.transfermanager.timeout.unit=HOURS

# Cell address of copymanager service
srm.service.copymanager=${dcache.service.copymanager}

# Timeout for copymanager requests
srm.service.copymanager.timeout=24
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.service.copymanager.timeout.unit=HOURS

# Cell address of billing service
srm.service.billing = ${dcache.service.billing}

# Cell address of pinmanager service
srm.service.pinmanager=${dcache.service.pinmanager}

# Timeout for pinmanager requests
srm.service.pinmanager.timeout=60
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.service.pinmanager.timeout.unit=MINUTES

# Cell address of poolmanager service
srm.service.poolmanager=${dcache.service.poolmanager}

# Timeout for poolmanager requests
srm.service.poolmanager.timeout = 300
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.service.poolmanager.timeout.unit=SECONDS

# Topic to which to publish credential service announcements
srm.credential-service.topic = ${dcache.credential-service.topic}


# ---- Login broker publishing
srm.loginbroker.update-topic= ${dcache.loginbroker.update-topic}
srm.loginbroker.request-topic= ${dcache.loginbroker.request-topic}
srm.loginbroker.tags= ${dcache.loginbroker.tags}
srm.loginbroker.update-period = ${dcache.loginbroker.update-period}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${dcache.loginbroker.update-period.unit})srm.loginbroker.update-period.unit = ${dcache.loginbroker.update-period.unit}
srm.loginbroker.update-threshold = ${dcache.loginbroker.update-threshold}

# Protocol version registered in login broker
srm.loginbroker.version = 1.1.1

# Protocol family registered in login broker
srm.loginbroker.family = srm

# Topic on which to expect pool monitor updates
srm.pool-monitor.topic = ${dcache.pool-monitor.topic}

# ---- Enable automatic creation of directories
#
# Allow automatic creation of directories via SRM.
#
#  allow=true, disallow=false
#
(one-of?true|false)srm.enable.recursive-directory-creation = true


# ---- Allow delete via SRM v1.1
#
# Allow deletion of files via the SRM v1.1 interface. This setting has no effect on
# the SRM v2.2 interface.
#
#  allow=true, disallow=false
#
(one-of?true|false)srm.enable.advisory-delete = true

# ---- Enable overwrite for SRM
#
# Defines how to respond to write requests to files that already exist.
#
# If srm.enable.overwrite is false, any request to overwrite an existing file will
# be rejected.
#
# If srm.enable.overwrite is enabled, the response depends on whether the SRM v1.1
# or SRM v2.2 interface is used. #For SRM v2.2, the write request contains a flag
# allowing the client to indicate whether it wants an existing file to be overwritten.
# If present, the flag is respected. If not present, the srm.enable.overwrite-by-default
# flag controls whether an existing file is overwritten or not. For SRM v1.1, the write
# request contains no such flag and srm.enable.overwrite-by-default controls whether an
# existing file is overwritten.
#
# Note that setting srm.enable.overwrite to false or srm.enable.overwrite-by-default
# to true violates the SRM 2.2 specification. That is, the defaults are required
# for standards-compliance.
#
(one-of?true|false|${dcache.enable.overwrite})\
srm.enable.overwrite=${dcache.enable.overwrite}
(one-of?true|false)\
srm.enable.overwrite-by-default = false

# ---- Number of concurrent file deletions
#
# To avoid starving other name space operations, the srm throttles
# bulk file deletion. This setting controls the number of concurrent
# file deletion requests submitted to PnfsManager.
#
srm.limits.remove-batch-size = 50

# path to host certificate
srm.authn.hostcert.cert=${dcache.authn.hostcert.cert}

# Host key
srm.authn.hostcert.key=${dcache.authn.hostcert.key}

# Host key refresh interval
srm.authn.hostcert.refresh=${dcache.authn.hostcert.refresh}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${dcache.authn.hostcert.refresh.unit})\
srm.authn.hostcert.refresh.unit=${dcache.authn.hostcert.refresh.unit}

# Path to CA directory
srm.authn.capath=${dcache.authn.capath}

# How often to check the CA certificates for updates
srm.authn.capath.refresh=${dcache.authn.capath.refresh}
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS|\
	${dcache.authn.capath.refresh.unit})\
srm.authn.capath.refresh.unit=${dcache.authn.capath.refresh.unit}

# Path to vomsdir directory
srm.authn.vomsdir=${dcache.authn.vomsdir}

# ---- Certificate Authority Namespace usage mode
(one-of?GLOBUS_EUGRIDPMA|EUGRIDPMA_GLOBUS|GLOBUS|EUGRIDPMA|GLOBUS_EUGRIDPMA_REQUIRE|EUGRIDPMA_GLOBUS_REQUIRE|GLOBUS_REQUIRE|EUGRIDPMA_REQUIRE|EUGRIDPMA_AND_GLOBUS|EUGRIDPMA_AND_GLOBUS_REQUIRE|IGNORE|${dcache.authn.namespace-mode})\
srm.authn.namespace-mode=${dcache.authn.namespace-mode}

# ---- Certificate Revocation List usage mode
(one-of?REQUIRE|IF_VALID|IGNORE|${dcache.authn.crl-mode})\
srm.authn.crl-mode=${dcache.authn.crl-mode}

# ---- On-line Certificate Status Protocol usage mode
(one-of?REQUIRE|IF_AVAILABLE|IGNORE|${dcache.authn.ocsp-mode})\
srm.authn.ocsp-mode=${dcache.authn.ocsp-mode}

# ---- GSI Delegation key pair caching lifetime
srm.authn.gsi.delegation.cache.lifetime = ${dcache.authn.gsi.delegation.cache.lifetime}
(one-of?MILLISECONDS|SECONDS|MINUTES|HOURS|DAYS|${dcache.authn.gsi.delegation.cache.lifetime.unit})\
srm.authn.gsi.delegation.cache.lifetime.unit = ${dcache.authn.gsi.delegation.cache.lifetime.unit}

# ---- Directory for delegated proxy certificates
#
# This is the directory in which the delegated user credentials will
# be stored as files. We recommend set permissions to 700 on this
# directory.
#
srm.user.credentials.directory = @srmUserCredentialsDirectory@

# ---- Database threads
#
# Database updates are queued and their execution is decoupled from
# the execution of SRM requests. The setting controls the number of
# the threads that will be dedicated to execution of these updates.
#
srm.limits.db.threads = 5

# ---- Database request queue depth
#
# Database updates are queued and their execution is decoupled from
# the execution of SRM requests. The setting controls the maximum
# length of the queue.
#
srm.limits.db.queue = 1000

# ---- srmClientDNSLookup
#
# Perform the lookup of the client hostname based on the client's IP
# address. The result is used in pool selection. If srmClientDNSLookup
# is set to false the client's IP address is used.
#
(one-of?true|false)srm.enable.client-dns-lookup = false

# set graceful shutdown timeout. If set, the internal doStop() method
# will not immediately stop the server. Instead, all Connectors will
# be closed so that new connections will not be accepted and all handlers that
# implement Server.Graceful will be put into the shutdown mode so that no
# new requests will be accepted, but existing requests can complete.
# The server will then wait the configured timeout before stopping.
srm.limits.jetty.graceful-shutdown = 2000
(one-of?MILLISECONDS|\
	SECONDS|\
	MINUTES|\
	HOURS|\
	DAYS)\
srm.limits.jetty.graceful-shutdown.unit=MILLISECONDS

# ---- Enable custom address resolution.
#
#   The srm.enable.custom-get-host-by-address property controls
#   whether to try a custom IP resolution if the standard InetAddress
#   method fails. Contributed by BNL.
#
(one-of?true|false)srm.enable.custom-get-host-by-address = false

# ----- Disallowed protocols for get requests
#
# Comma separated list of protocols that will not be used even if both
# client and server support it.
#
srm.protocols.disallowed.get = file,${srm.loginbroker.family}

# ----- Disallowed protocols for put requests
#
# Comma separated list of protocols that will not be used even if both
# client and server support it.
#
srm.protocols.disallowed.put = http,file,${srm.loginbroker.family}

# ----- Preferred transfer protocols
#
# Ordered comma separated list of preferred transfer protocols. If
# supported by both client and server, protocols early in this list
# will be preferred to protocols later in the list or not in the
# list at all. If no common protocol is found, the first protocol in
# the clients list supported by the server is used.
#
# Setting this property to a non-empty list means the clients protocol
# preference is ignored, which is usually not a good thing. The classic
# use case for this property is as a workaround for clients that assign
# high priority to protocols the server admin tries to avoid.
srm.protocols.preferred =

# ---- Filter doors by tags
#
# Comma separated list of tags. Restricts doors to those that publish
# at least one of these tags.
#
srm.protocols.tags = srm

# ---- Number of doors in random door selection
#
# SRM will order doors according to their load and select certain
# number of the least loaded and then randomly choose which one to
# use.
#
srm.protocols.population-size = 5



# ----- Whether to pin disk files
#
# The SRM protocol allows files to be pinned. The pin suppresses
# automatic garbage collection for the lifetime of the pin.
#
# Since dCache pools may be configured to only serve particular types
# of requests and not every pool may be configured to serve a
# particular read request, strict protocol compliance requires pinning
# even for disk only files.
#
# Often strict protocol compliance is however unnecessary, or disk
# files may be known to always be on read pools. In those cases one
# can skip the pinning step and thus reduce the latency of
# srmPrepareToGet request.
#
# When this property is set to false, files with access latency of
# ONLINE will not be pinned. If all files in the system have access
# latency of ONLINE, then the SRM will not use the pin manager at
# all. Note that when this property is set to false, orphaned file
# location entries in the name space will not validated during the
# srmPrepareToGet processing. The consequence is that the
# srmPrepareToGet may succeed for a lost and the subsequence file
# transfer will fail.
#
(one-of?true|false)srm.enable.pin-online-files = true

# ---- Quality of Service plugins
#
#  dCache SRM supports plugins that allow bandwidth reservation prior
#  to transferring files.  Support for two projects is provide with
#  dCache:  TeraPaths and Lamda Station.
#
#  TeraPaths:
#
#      The TeraPaths project investigates the use and integration of
#      Differentiated Services-based LAN QoS and WAN MPLS technologies
#      in data-intensive distributed computing environments, such as
#      the RHIC/ATLAS computing environment.
#
#      For more details see https://www.racf.bnl.gov/terapaths
#
#      To enable the Terapath plugin define:
#
#      srm.plugins.qos.class = org.dcache.srm.qos.terapaths.TerapathsPlugin
#      srm.plugins.qos.config.file = ${dcache.paths.config}/terapaths.properties
#
#  Lambda Station:
#
#      The Lambda Station project is aimed to enable dynamic
#      allocation of alternate network paths for traffic of production
#      SciDAC applications and to forward designated flows across LAN,
#      negotiates with reservation and provisioning systems of WAN
#      control planes, be it based on SONET channels, demand tunnels,
#      or dynamic circuit networks.
#
#      For more details see http://www.lambdastation.org/
#
#      To enable the Lamda Station plugin define:
#
#      srm.plugins.qos.class = org.dcache.srm.qos.terapaths.LambdaStation
#      srm.plugins.qos.config.file = ${dcache.paths.config}/lambdastation.properties
#
srm.plugins.qos.class =

srm.plugins.qos.config.file =

(one-of?true|false|${dcache.enable.space-reservation})\
srm.enable.space-reservation=${dcache.enable.space-reservation}


#  Security related properties
srm.authn.ciphers = ${dcache.authn.ciphers}

#
# ---- Third-party transfers
#
#  Third-party copying is when a client requests that data is sent
#  between this dCache cluster and some other storage system without
#  that client acting as an intermediate for the flow of data.
#
#  With a third-party copy initiatied through the SRM protocol, the
#  client may either specify a protocol-specific endpoint (e.g.,
#  'https://storage.example.org/path/to/remote-file'), or an SRM
#  endpoint (e.g., 'srm://storage.example.org/path/to/remote-file').
#  If an SRM endpoint is specified then dCache will negotiate with the
#  remote server to find the best available transfer protocol.
#
#  dCache will try to verify the integrity of transferred data by
#  comparing locally generated checksum values with that obtained from
#  the remote server.  If the transfer did not use the SRM protocol
#  then checksums can only be obtained via the transfer protocol.
#
#  If the transfer protocol is HTTP then RFC 3230 allows dCache to
#  discover checksums for the remote file.  With this, dCache can
#  learn if the file was corrupted during transfer.  If the remote
#  server supports RFC 3230 and the remote server uses a compatible
#  checksum algorithm then dCache will always verify the data
#  integrity.
#
#  Although dCache supports RFC 3230, most HTTP and WebDAV servers
#  currently do not.  It is also possible that, although the remote
#  server supports RFC 3230, the supplied checksum cannot be used by
#  dCache.  When transferring data with such a server, dCache can
#  either transfer the file's data without checksum verification or
#  fail the request.
#
#  The SRM protocol allows the client to steer the transfer by setting
#  ExtraInfo options.  dCache accepts the 'verify' ExtraInfo option
#  with a value of 'true' or 'false'.  If 'true' then checksum
#  verification is required for the transfers and the failure to
#  obtain a suitable checksum will fail the transfer.  If 'false' then
#  dCache will still attempt to verify data integrety but the transfer
#  will not fail because of dCache was unable to verify the data
#  integrety by checking a checksum.  See SRM client documentation for
#  details on how to set ExtraInfo options.
#
#  If the client leaves this option unspecified then the following
#  property's value is used as a default.
#
(one-of?true|false)srm.enable.third-party.requiring-verification-by-default = true

#
#  SRM ping ExtraInfo
#
#  The SRM 'ping' command allows the client to check that the server
#  is alive.  In addition to demonstrating the basic health of the
#  server, the response contains information as a list of key-value
#  pairs.
#
#  Sites can provide additional information by configuring properties
#  with a name that starts 'srm.ping-extra-info!'.  The ExtraInfo key
#  is the property name without this prefix and the ExtraInfo value is
#  the property's value.
#
(prefix)srm.ping-extra-info = The ExtraInfo items in an srmPing response.
srm.ping-extra-info!backend_type = dCache
srm.ping-extra-info!backend_version = ${dcache.version}


#
#  Estimated minimum bandwidth
#
#  SRM requests have a lifetime; in particular, for GET, PUT and COPY
#  requests, these lifetimes include the time during which files may
#  be transferred.
#
#  Nothing happens if the lifetime expires during a download (GET)
#  request; however, elapsed lifetimes will result in failed upload
#  requests (PUT) and third-party transfer (COPY) requests.
#
#  Some clients have hard-coded, short lifetimes for their requests.
#  As a consequence, they experience (often sporadic) failures
#  depending on the size of the file(s) involved, the network
#  conditions, and the concurrent load on pools.  This makes such
#  problems difficult to diagnose and the overall service unreliable.
#
#  As a work-around, a conservative estimate of the available
#  bandwidth is used to calculate a reasonable upper limit on the
#  transfer time.  This upper limit assumes that bulk requests are
#  transferred concurrently.  If the request lifetime is less than
#  this upper limit then the upper limit is used instead.
#
#  The value is a positive integer representing the minimum expected
#  bandwidth of a transfer (including both IO bandwidth of the pools
#  and network bandwidth), with value in MiB/s.  A value of 0 switches
#  off this feature.
#
srm.minimum-bandwidth = 0

#
#   Document which TCP ports are opened
#
(immutable)srm.net.ports.tcp=${srm.net.port}




(obsolete)srm.request.threads = See srm.request.*.max-inprogress
(obsolete)srm.request.get.threads = See srm.request.*.max-inprogress
(obsolete)srm.request.bring-online.threads = See srm.request.*.max-inprogress
(obsolete)srm.request.put.threads = See srm.request.*.max-inprogress
(obsolete)srm.request.copy.threads = See srm.request.*.max-inprogress
(obsolete)srm.request.ls.threads = See srm.request.*.max-inprogress
(obsolete)srm.request.reserve-space.threads = See srm.request.*.max-inprogress
(obsolete)srm.request.retries=10
(obsolete)srm.request.get.retries =
(obsolete)srm.request.bring-online.retries =
(obsolete)srm.request.put.retries =
(obsolete)srm.request.copy.retries =
(obsolete)srm.request.ls.retries =
(obsolete)srm.request.reserve-space.retries =
(obsolete)srm.request.retry-timeout =
(obsolete)srm.request.retry-timeout.unit =
(obsolete)srm.request.get.retry-timeout =
(obsolete)srm.request.get.retry-timeout.unit=
(obsolete)srm.request.bring-online.retry-timeout =
(obsolete)srm.request.bring-online.retry-timeout.unit=
(obsolete)srm.request.put.retry-timeout =
(obsolete)srm.request.put.retry-timeout.unit=
(obsolete)srm.request.copy.retry-timeout =
(obsolete)srm.request.copy.retry-timeout.unit=
(obsolete)srm.request.ls.retry-timeout =
(obsolete)srm.request.ls.retry-timeout.unit=
(obsolete)srm.request.reserve-space.retry-timeout =
(obsolete)srm.request.reserve-space.retry-timeout.unit=
(obsolete)srm.request.max-by-same-user =
(obsolete)srm.request.get.max-by-same-user =
(obsolete)srm.request.bring-online.max-by-same-user =
(obsolete)srm.request.put.max-by-same-user =
(obsolete)srm.request.copy.max-by-same-user =
(obsolete)srm.request.ls.max-by-same-user =
(obsolete)srm.request.reserve-space.max-by-same-user =
